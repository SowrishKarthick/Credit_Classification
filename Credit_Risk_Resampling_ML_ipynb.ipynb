{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oqr3QcdsZ0aE"
      },
      "source": [
        "#  Credit Risk Prediction using Machine Learning and Resampling Techniques\n",
        "---\n",
        "**Objective:** Predict whether a loan applicant is a good or bad credit risk using multiple ML algorithms, comparing Random Oversampling and SMOTE for class imbalance handling.\n",
        "\n",
        "**Dataset:** [UCI Statlog German Credit Data](https://archive.ics.uci.edu/dataset/144/statlog+german+credit+data)\n"
      ],
      "id": "Oqr3QcdsZ0aE"
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "RR7l1dIKZ0aU"
      },
      "source": [
        "# Install dependencies\n",
        "!pip install imbalanced-learn xgboost tqdm seaborn matplotlib\n",
        "# Install EBM model (Explainable Boosting Machine)\n",
        "!pip install interpret\n"
      ],
      "id": "RR7l1dIKZ0aU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjWx4_g7Z0aX"
      },
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from xgboost import XGBClassifier\n",
        "from interpret.glassbox import ExplainableBoostingClassifier\n",
        "\n",
        "\n",
        "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
        "from tqdm import tqdm"
      ],
      "id": "bjWx4_g7Z0aX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bgL-nSmZ0aY"
      },
      "source": [
        "### Load Dataset"
      ],
      "id": "_bgL-nSmZ0aY"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUINIScLZ0aZ"
      },
      "source": [
        "url = '/content/drive/MyDrive/statlog/german.data'  # update path if necessary\n",
        "column_names = [\n",
        "    'status', 'duration', 'credit_history', 'purpose', 'credit_amount', 'savings',\n",
        "    'employment', 'installment_rate', 'personal_status', 'guarantors', 'residence_since',\n",
        "    'property', 'age', 'other_installment_plans', 'housing', 'existing_credits',\n",
        "    'job', 'liable_people', 'telephone', 'foreign_worker', 'target'\n",
        "]\n",
        "\n",
        "df = pd.read_csv(url, sep=' ', names=column_names)\n",
        "df['target'] = df['target'].map({1: 0, 2: 1})  # 0=Good, 1=Bad\n",
        "df = pd.get_dummies(df, drop_first=True)\n",
        "\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "print('Data loaded and preprocessed successfully.')"
      ],
      "id": "bUINIScLZ0aZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wc5Ko1iJZ0aa"
      },
      "source": [
        "###  Define Models"
      ],
      "id": "Wc5Ko1iJZ0aa"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oH-nfLjZ0ab"
      },
      "source": [
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
        "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
        "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
        "    'AdaBoost': AdaBoostClassifier(random_state=42),\n",
        "    'KNN': KNeighborsClassifier(),\n",
        "    'Naive Bayes': GaussianNB(),\n",
        "    'SVM (RBF)': SVC(kernel='rbf', probability=True, random_state=42),\n",
        "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),Preview\n",
        "    'Explainable Boosting (EBM)' : ExplainableBoostingClassifier(random_state=42)\n",
        "\n",
        "\n",
        "}"
      ],
      "id": "6oH-nfLjZ0ab",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvz4UImsZ0ab"
      },
      "source": [
        "###  Evaluation Function"
      ],
      "id": "mvz4UImsZ0ab"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ol9vma_WZ0ab"
      },
      "source": [
        "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
        "    try:\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        if hasattr(model, 'predict_proba'):\n",
        "            y_prob = model.predict_proba(X_test)[:, 1]\n",
        "        else:\n",
        "            # Handle models without predict_proba (e.g., pyGAM)\n",
        "            y_prob = model.predict(X_test)\n",
        "            y_prob = np.nan_to_num(y_prob, nan=0.5, posinf=1.0, neginf=0.0)\n",
        "            y_prob = np.clip(y_prob, 0, 1)\n",
        "\n",
        "        y_pred = (y_prob >= 0.5).astype(int)\n",
        "\n",
        "        return {\n",
        "            'Accuracy': accuracy_score(y_test, y_pred),\n",
        "            'Precision': precision_score(y_test, y_pred),\n",
        "            'Recall': recall_score(y_test, y_pred),\n",
        "            'F1': f1_score(y_test, y_pred),\n",
        "            'ROC-AUC': roc_auc_score(y_test, y_prob)\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ {type(model).__name__} failed: {e}\")\n",
        "        return {\n",
        "            'Accuracy': np.nan, 'Precision': np.nan, 'Recall': np.nan,\n",
        "            'F1': np.nan, 'ROC-AUC': np.nan\n",
        "        }\n"
      ],
      "id": "Ol9vma_WZ0ab",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hoXQBT_Z0ad"
      },
      "source": [
        "###  Sampling Methods and Model Evaluation"
      ],
      "id": "0hoXQBT_Z0ad"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgrGaiDGZ0ad"
      },
      "source": [
        "samplers = {\n",
        "    'Original': None,\n",
        "    'RandomOverSampler': RandomOverSampler(random_state=42),\n",
        "    'SMOTE': SMOTE(random_state=42)\n",
        "}\n",
        "\n",
        "results = []\n",
        "for sampler_name, sampler in samplers.items():\n",
        "    if sampler:\n",
        "        X_res, y_res = sampler.fit_resample(X_train, y_train)\n",
        "    else:\n",
        "        X_res, y_res = X_train, y_train\n",
        "\n",
        "    print(f'\\n=== Sampling: {sampler_name} ===')\n",
        "    for name, model in tqdm(models.items()):\n",
        "        metrics = evaluate_model(model, X_res, y_res, X_test, y_test)\n",
        "        metrics.update({'Model': name, 'Sampling': sampler_name})\n",
        "        results.append(metrics)\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df = results_df[['Model', 'Sampling', 'Accuracy', 'Precision', 'Recall', 'F1', 'ROC-AUC']]\n",
        "display(results_df.sort_values(['Sampling', 'ROC-AUC'], ascending=[True, False]))"
      ],
      "id": "FgrGaiDGZ0ad",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dMh53orZ0ae"
      },
      "source": [
        "###  Visualization"
      ],
      "id": "0dMh53orZ0ae"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybCZ-6CXZ0ae"
      },
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "sns.barplot(data=results_df, x='Model', y='ROC-AUC', hue='Sampling')\n",
        "plt.xticks(rotation=45)\n",
        "plt.title('Model Performance Comparison by Sampling Method')\n",
        "plt.show()"
      ],
      "id": "ybCZ-6CXZ0ae",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76eZiWWIZ0af"
      },
      "source": [
        "###  Confusion Matrix for Best Model"
      ],
      "id": "76eZiWWIZ0af"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jF-ow9m3Z0af"
      },
      "source": [
        "best = results_df.sort_values('ROC-AUC', ascending=False).iloc[0]\n",
        "print(f\"Best Model: {best['Model']} | Sampling: {best['Sampling']}\")\n",
        "\n",
        "sampler = samplers[best['Sampling']]\n",
        "if sampler:\n",
        "    X_res, y_res = sampler.fit_resample(X_train, y_train)\n",
        "else:\n",
        "    X_res, y_res = X_train, y_train\n",
        "\n",
        "model = models[best['Model']]\n",
        "model.fit(X_res, y_res)\n",
        "\n",
        "if hasattr(model, 'predict_proba'):\n",
        "    y_pred = (model.predict_proba(X_test)[:,1] >= 0.5).astype(int)\n",
        "else:\n",
        "    y_pred = (model.predict(X_test) >= 0.5).astype(int)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Purples')\n",
        "plt.title(f\"Confusion Matrix - {best['Model']} ({best['Sampling']})\")\n",
        "plt.show()"
      ],
      "id": "jF-ow9m3Z0af",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}